{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cd1a04e",
   "metadata": {},
   "source": [
    "<h1> Create New Design Ideas - Image Generation </h1>\n",
    "<br>\n",
    "\n",
    "Before starting, please make sure this notebook is using **conda_python3** kernel from the top right!\n",
    "\n",
    "Run all the cells and inspect the output of each cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181e96a5",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this notebook, you will generate new design idea based on the existing product image from the catalog. For this feature, we will invoke the Bedrock API directly without Langchain using Bedrock's [InvokeModel](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-runtime/client/invoke_model.html) API. \n",
    "\n",
    "We will use Stability AI's [Stable Diffusion](https://aws.amazon.com/bedrock/stable-diffusion/) model from Bedrock that supports Text-To-Image and Image-To-Image transformations. We pass two optional prompt inputs to the model.\n",
    "\n",
    "1. **Prompt** or positive prompt will be used for creating new ideas from the existing image. We'll provide a text description of what image should be generated. For example: \"*add animal prints to the shirt*\". \n",
    "\n",
    "But what if we want to nudge the model to *avoid* specific content or style choices? Because image generation models are typically trained from image descriptions, trying to directly specify what you don't want in the prompt (for example: a buffalo without horns) doesn't usually work well: It would be very unusual to describe an image by the things it isn't! That is why we use the negative prompts. \n",
    "\n",
    "2. **Negative prompt** removes objects or styles in a way that may not be possible with positive prompt alone. For example: \"*horns*\", \"*bad quality*\" or \"*poorly rendered*\". Stable diffusion model understands this prompt better than asking directly in the positive prompt \"*do not generate poorly rendered image*\" or \"*buffalo with no horns*\". \n",
    "\n",
    "We can also specify certain [style presets](https://platform.stability.ai/docs/release-notes#style-presets) to help influence the generation. You can experiment with different style presets from the **Explore** section. \n",
    "\n",
    "![Image Generation](../images/image-generation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5e326a",
   "metadata": {},
   "source": [
    "### Install required dependencies\n",
    "\n",
    "**Important:** You may see an error or a warning that \"you may need to restart the kernel\" from the following cell. **Ignore** and proceed with the next cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f86df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --quiet --no-build-isolation --upgrade \\\n",
    "    \"boto3==1.28.63\" \\\n",
    "    \"awscli==1.29.63\" \\\n",
    "    \"botocore==1.31.63\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bbc91b",
   "metadata": {},
   "source": [
    "<h3> Import required packages </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1efe7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "# For image operations\n",
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "import requests\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock, print_ww"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775e1190",
   "metadata": {},
   "source": [
    "<h3> Initialize Bedrock client </h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80f14e4",
   "metadata": {},
   "outputs": [],
   "source": [
    " boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619d8c44",
   "metadata": {},
   "source": [
    "<p>Create a function to convert an image into a base64 string since Stabile Diffusion Model expects the image to be in base64 string format</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7654ed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_base64(img) -> str:\n",
    "    if isinstance(img, str):\n",
    "        if os.path.isfile(img):\n",
    "            with open(img, \"rb\") as f:\n",
    "                return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"File {img} does not exist\")\n",
    "    elif isinstance(img, Image.Image):\n",
    "        buffer = io.BytesIO()\n",
    "        img.save(buffer, format=\"PNG\")\n",
    "        return base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "    else:\n",
    "        raise ValueError(f\"Expected str (filename) or PIL Image. Got {type(img)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebd501a",
   "metadata": {},
   "source": [
    "### Read a sample product image\n",
    "\n",
    "**Note:** We are using one of the images from the <a href=\"https://github.com/zalandoresearch/feidegger/tree/master\">FEIDEGGER</a> dataset as an example. In the actual retail website, you will use the product image from the catalog. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895df4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://img01.ztat.net/article/spp-media-p1/3c8812d8b6233a55a5da06b19d780302/dc58460c157b426b817f13e7a2f087c5.jpg\"\n",
    "\n",
    "response = requests.get(image_url)\n",
    "image = Image.open(io.BytesIO(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ad540f",
   "metadata": {},
   "source": [
    "### Resize Image\n",
    "\n",
    "Resize the image product image to 512x512 and convert to base64 string format to comply with the requirements for Stable Diffusion. \n",
    "\n",
    "Although the current Stable Diffusion model defaults to a square resolution of 512px x 512px, it is capable of generating images at higher resolutions and non-squared aspect ratios. As shown below, the width of the image was set to 768px and the height remains at its default value of 512px."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = image.resize((512,512))\n",
    "resize.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93e3ae9",
   "metadata": {},
   "source": [
    "Convert this image to a base 64 string to pass into the model </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638c4d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_image_b64 = image_to_base64(resize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa962455",
   "metadata": {},
   "source": [
    "### Input prompts \n",
    "\n",
    "These are the image prompts and the negative prompts we will be passing to the Stable Diffusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a1c7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This prompt is used to generate new ideas from the existing image\n",
    "change_prompt = \"add floral prints to dress\"\n",
    "\n",
    "# Negative prompts that will be given -1.0 weight while generating new image\n",
    "negative_prompts = ['poorly rendered',\n",
    "                    'low quality',\n",
    "                    'disfigured',\n",
    "                    'disproportional']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9aeb3f",
   "metadata": {},
   "source": [
    "### Compose request to pass to Stable Diffusion Model\n",
    "\n",
    "This request includes our input prompts (prompt, negative prompt) as well as the Stable Diffusion's [inference parameters](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-diffusion.html). **Note:** We describe these inference parameters in the **Explore** section of the workshop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c8cd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_request = json.dumps({\n",
    "                    \"text_prompts\": (\n",
    "                        [{\"text\": change_prompt, \"weight\": 1.0}]\n",
    "                        + [{\"text\": negprompt, \"weight\": -1.0} for negprompt in negative_prompts]\n",
    "                    ),\n",
    "                    \"cfg_scale\": 10,\n",
    "                    \"init_image\": init_image_b64,\n",
    "                    \"seed\": 0,\n",
    "                    \"start_schedule\": 0.5,\n",
    "                    \"steps\": 30,\n",
    "                    \"style_preset\": \"photographic\",\n",
    "                    \"image_strength\":0.5,\n",
    "                    \"denoising_strength\": 0.5\n",
    "                })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaefe11",
   "metadata": {},
   "source": [
    "### Call Bedrock to generate new image\n",
    "\n",
    "Notice that we directly use the InvokeModel API from Bedrock. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9615af",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = boto3_bedrock.invoke_model(body=sd_request, modelId=\"stability.stable-diffusion-xl-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65879a6",
   "metadata": {},
   "source": [
    "### Render the newly generated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae68c393",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_body = json.loads(response.get('body').read())\n",
    "genimage_b64_str = response_body[\"artifacts\"][0].get(\"base64\")\n",
    "genimage = Image.open(io.BytesIO(base64.decodebytes(bytes(genimage_b64_str, \"utf-8\"))))\n",
    "genimage.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9aa1d2",
   "metadata": {},
   "source": [
    "<h3> You've successfully created new design ideas for a product with Amazon Bedrock!</h3>\n",
    "\n",
    "Please stop the notebook kernel by selecting **Kernel -> Interrupt**.\n",
    "\n",
    "#### Now, let's integrate this feature into our retail web application. Please go back to Workshop Studio and follow the instructions to build this feature using your Cloud9 IDE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de68cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
